{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b180a6f1",
   "metadata": {},
   "source": [
    "## Red Wine Quality Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89b9fb1",
   "metadata": {},
   "source": [
    "There is 11 different attributs that decide the quality of red wine in this dataset.\n",
    "- Fixed acidity\n",
    "- Volatile acidity\n",
    "- Citric acid\n",
    "- Residual sugar\n",
    "- Chlorides\n",
    "- Free sulfur dioxide\n",
    "- Total sulfur dioxide\n",
    "- Density\n",
    "- pH\n",
    "- Sulphates\n",
    "- Alcohol\n",
    "\n",
    "We want to predict the quality of red wine depending on those attributes. The quality of red wine in this dataset is a number between 0 and 10."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Requirements"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "df71a6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn import tree, metrics\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, mean_absolute_error, mean_squared_error\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Collection & Data Preparation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be433e4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n0               7.4             0.700         0.00             1.9      0.076   \n1               7.8             0.880         0.00             2.6      0.098   \n2               7.8             0.760         0.04             2.3      0.092   \n3              11.2             0.280         0.56             1.9      0.075   \n4               7.4             0.700         0.00             1.9      0.076   \n...             ...               ...          ...             ...        ...   \n1594            6.2             0.600         0.08             2.0      0.090   \n1595            5.9             0.550         0.10             2.2      0.062   \n1596            6.3             0.510         0.13             2.3      0.076   \n1597            5.9             0.645         0.12             2.0      0.075   \n1598            6.0             0.310         0.47             3.6      0.067   \n\n      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n0                    11.0                  34.0  0.99780  3.51       0.56   \n1                    25.0                  67.0  0.99680  3.20       0.68   \n2                    15.0                  54.0  0.99700  3.26       0.65   \n3                    17.0                  60.0  0.99800  3.16       0.58   \n4                    11.0                  34.0  0.99780  3.51       0.56   \n...                   ...                   ...      ...   ...        ...   \n1594                 32.0                  44.0  0.99490  3.45       0.58   \n1595                 39.0                  51.0  0.99512  3.52       0.76   \n1596                 29.0                  40.0  0.99574  3.42       0.75   \n1597                 32.0                  44.0  0.99547  3.57       0.71   \n1598                 18.0                  42.0  0.99549  3.39       0.66   \n\n      alcohol  quality  \n0         9.4        5  \n1         9.8        5  \n2         9.8        5  \n3         9.8        6  \n4         9.4        5  \n...       ...      ...  \n1594     10.5        5  \n1595     11.2        6  \n1596     11.0        6  \n1597     10.2        5  \n1598     11.0        6  \n\n[1599 rows x 12 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>fixed acidity</th>\n      <th>volatile acidity</th>\n      <th>citric acid</th>\n      <th>residual sugar</th>\n      <th>chlorides</th>\n      <th>free sulfur dioxide</th>\n      <th>total sulfur dioxide</th>\n      <th>density</th>\n      <th>pH</th>\n      <th>sulphates</th>\n      <th>alcohol</th>\n      <th>quality</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>7.4</td>\n      <td>0.700</td>\n      <td>0.00</td>\n      <td>1.9</td>\n      <td>0.076</td>\n      <td>11.0</td>\n      <td>34.0</td>\n      <td>0.99780</td>\n      <td>3.51</td>\n      <td>0.56</td>\n      <td>9.4</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7.8</td>\n      <td>0.880</td>\n      <td>0.00</td>\n      <td>2.6</td>\n      <td>0.098</td>\n      <td>25.0</td>\n      <td>67.0</td>\n      <td>0.99680</td>\n      <td>3.20</td>\n      <td>0.68</td>\n      <td>9.8</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>7.8</td>\n      <td>0.760</td>\n      <td>0.04</td>\n      <td>2.3</td>\n      <td>0.092</td>\n      <td>15.0</td>\n      <td>54.0</td>\n      <td>0.99700</td>\n      <td>3.26</td>\n      <td>0.65</td>\n      <td>9.8</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>11.2</td>\n      <td>0.280</td>\n      <td>0.56</td>\n      <td>1.9</td>\n      <td>0.075</td>\n      <td>17.0</td>\n      <td>60.0</td>\n      <td>0.99800</td>\n      <td>3.16</td>\n      <td>0.58</td>\n      <td>9.8</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7.4</td>\n      <td>0.700</td>\n      <td>0.00</td>\n      <td>1.9</td>\n      <td>0.076</td>\n      <td>11.0</td>\n      <td>34.0</td>\n      <td>0.99780</td>\n      <td>3.51</td>\n      <td>0.56</td>\n      <td>9.4</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1594</th>\n      <td>6.2</td>\n      <td>0.600</td>\n      <td>0.08</td>\n      <td>2.0</td>\n      <td>0.090</td>\n      <td>32.0</td>\n      <td>44.0</td>\n      <td>0.99490</td>\n      <td>3.45</td>\n      <td>0.58</td>\n      <td>10.5</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>1595</th>\n      <td>5.9</td>\n      <td>0.550</td>\n      <td>0.10</td>\n      <td>2.2</td>\n      <td>0.062</td>\n      <td>39.0</td>\n      <td>51.0</td>\n      <td>0.99512</td>\n      <td>3.52</td>\n      <td>0.76</td>\n      <td>11.2</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>1596</th>\n      <td>6.3</td>\n      <td>0.510</td>\n      <td>0.13</td>\n      <td>2.3</td>\n      <td>0.076</td>\n      <td>29.0</td>\n      <td>40.0</td>\n      <td>0.99574</td>\n      <td>3.42</td>\n      <td>0.75</td>\n      <td>11.0</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>1597</th>\n      <td>5.9</td>\n      <td>0.645</td>\n      <td>0.12</td>\n      <td>2.0</td>\n      <td>0.075</td>\n      <td>32.0</td>\n      <td>44.0</td>\n      <td>0.99547</td>\n      <td>3.57</td>\n      <td>0.71</td>\n      <td>10.2</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>1598</th>\n      <td>6.0</td>\n      <td>0.310</td>\n      <td>0.47</td>\n      <td>3.6</td>\n      <td>0.067</td>\n      <td>18.0</td>\n      <td>42.0</td>\n      <td>0.99549</td>\n      <td>3.39</td>\n      <td>0.66</td>\n      <td>11.0</td>\n      <td>6</td>\n    </tr>\n  </tbody>\n</table>\n<p>1599 rows Ã— 12 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/winequality-red.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1599 entries, 0 to 1598\n",
      "Data columns (total 12 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   fixed acidity         1599 non-null   float64\n",
      " 1   volatile acidity      1599 non-null   float64\n",
      " 2   citric acid           1599 non-null   float64\n",
      " 3   residual sugar        1599 non-null   float64\n",
      " 4   chlorides             1599 non-null   float64\n",
      " 5   free sulfur dioxide   1599 non-null   float64\n",
      " 6   total sulfur dioxide  1599 non-null   float64\n",
      " 7   density               1599 non-null   float64\n",
      " 8   pH                    1599 non-null   float64\n",
      " 9   sulphates             1599 non-null   float64\n",
      " 10  alcohol               1599 non-null   float64\n",
      " 11  quality               1599 non-null   int64  \n",
      "dtypes: float64(11), int64(1)\n",
      "memory usage: 150.0 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "093afd44",
   "metadata": {},
   "source": [
    "We can treat this problem either as a classification problem or as a regression problem since red wine quality is nothing but a real number between 0 and 10. \n",
    "\n",
    "Here, I decided to treat it as a classification problem.\n",
    "\n",
    "This dataset consists of only 6 types of quality values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "       fixed acidity  volatile acidity  citric acid  residual sugar  \\\ncount    1599.000000       1599.000000  1599.000000     1599.000000   \nmean        8.319637          0.527821     0.270976        2.538806   \nstd         1.741096          0.179060     0.194801        1.409928   \nmin         4.600000          0.120000     0.000000        0.900000   \n25%         7.100000          0.390000     0.090000        1.900000   \n50%         7.900000          0.520000     0.260000        2.200000   \n75%         9.200000          0.640000     0.420000        2.600000   \nmax        15.900000          1.580000     1.000000       15.500000   \n\n         chlorides  free sulfur dioxide  total sulfur dioxide      density  \\\ncount  1599.000000          1599.000000           1599.000000  1599.000000   \nmean      0.087467            15.874922             46.467792     0.996747   \nstd       0.047065            10.460157             32.895324     0.001887   \nmin       0.012000             1.000000              6.000000     0.990070   \n25%       0.070000             7.000000             22.000000     0.995600   \n50%       0.079000            14.000000             38.000000     0.996750   \n75%       0.090000            21.000000             62.000000     0.997835   \nmax       0.611000            72.000000            289.000000     1.003690   \n\n                pH    sulphates      alcohol      quality  \ncount  1599.000000  1599.000000  1599.000000  1599.000000  \nmean      3.311113     0.658149    10.422983     5.636023  \nstd       0.154386     0.169507     1.065668     0.807569  \nmin       2.740000     0.330000     8.400000     3.000000  \n25%       3.210000     0.550000     9.500000     5.000000  \n50%       3.310000     0.620000    10.200000     6.000000  \n75%       3.400000     0.730000    11.100000     6.000000  \nmax       4.010000     2.000000    14.900000     8.000000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>fixed acidity</th>\n      <th>volatile acidity</th>\n      <th>citric acid</th>\n      <th>residual sugar</th>\n      <th>chlorides</th>\n      <th>free sulfur dioxide</th>\n      <th>total sulfur dioxide</th>\n      <th>density</th>\n      <th>pH</th>\n      <th>sulphates</th>\n      <th>alcohol</th>\n      <th>quality</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>1599.000000</td>\n      <td>1599.000000</td>\n      <td>1599.000000</td>\n      <td>1599.000000</td>\n      <td>1599.000000</td>\n      <td>1599.000000</td>\n      <td>1599.000000</td>\n      <td>1599.000000</td>\n      <td>1599.000000</td>\n      <td>1599.000000</td>\n      <td>1599.000000</td>\n      <td>1599.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>8.319637</td>\n      <td>0.527821</td>\n      <td>0.270976</td>\n      <td>2.538806</td>\n      <td>0.087467</td>\n      <td>15.874922</td>\n      <td>46.467792</td>\n      <td>0.996747</td>\n      <td>3.311113</td>\n      <td>0.658149</td>\n      <td>10.422983</td>\n      <td>5.636023</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>1.741096</td>\n      <td>0.179060</td>\n      <td>0.194801</td>\n      <td>1.409928</td>\n      <td>0.047065</td>\n      <td>10.460157</td>\n      <td>32.895324</td>\n      <td>0.001887</td>\n      <td>0.154386</td>\n      <td>0.169507</td>\n      <td>1.065668</td>\n      <td>0.807569</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>4.600000</td>\n      <td>0.120000</td>\n      <td>0.000000</td>\n      <td>0.900000</td>\n      <td>0.012000</td>\n      <td>1.000000</td>\n      <td>6.000000</td>\n      <td>0.990070</td>\n      <td>2.740000</td>\n      <td>0.330000</td>\n      <td>8.400000</td>\n      <td>3.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>7.100000</td>\n      <td>0.390000</td>\n      <td>0.090000</td>\n      <td>1.900000</td>\n      <td>0.070000</td>\n      <td>7.000000</td>\n      <td>22.000000</td>\n      <td>0.995600</td>\n      <td>3.210000</td>\n      <td>0.550000</td>\n      <td>9.500000</td>\n      <td>5.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>7.900000</td>\n      <td>0.520000</td>\n      <td>0.260000</td>\n      <td>2.200000</td>\n      <td>0.079000</td>\n      <td>14.000000</td>\n      <td>38.000000</td>\n      <td>0.996750</td>\n      <td>3.310000</td>\n      <td>0.620000</td>\n      <td>10.200000</td>\n      <td>6.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>9.200000</td>\n      <td>0.640000</td>\n      <td>0.420000</td>\n      <td>2.600000</td>\n      <td>0.090000</td>\n      <td>21.000000</td>\n      <td>62.000000</td>\n      <td>0.997835</td>\n      <td>3.400000</td>\n      <td>0.730000</td>\n      <td>11.100000</td>\n      <td>6.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>15.900000</td>\n      <td>1.580000</td>\n      <td>1.000000</td>\n      <td>15.500000</td>\n      <td>0.611000</td>\n      <td>72.000000</td>\n      <td>289.000000</td>\n      <td>1.003690</td>\n      <td>4.010000</td>\n      <td>2.000000</td>\n      <td>14.900000</td>\n      <td>8.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "fixed acidity           0\nvolatile acidity        0\ncitric acid             0\nresidual sugar          0\nchlorides               0\nfree sulfur dioxide     0\ntotal sulfur dioxide    0\ndensity                 0\npH                      0\nsulphates               0\nalcohol                 0\nquality                 0\ndtype: int64"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# missing values\n",
    "df.isnull().sum()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "There is any missing values in this dataset, we can directly go to the feature engineering part."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='quality', data=df)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We know that the quality of red wine is a value between 0 and 10. Here wa can see that there is either any 0, 1, 2 or 9, 10 values.\n",
    "I will split these values into bad (0) or good (1) quality."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n0               7.4             0.700         0.00             1.9      0.076   \n1               7.8             0.880         0.00             2.6      0.098   \n2               7.8             0.760         0.04             2.3      0.092   \n3              11.2             0.280         0.56             1.9      0.075   \n4               7.4             0.700         0.00             1.9      0.076   \n...             ...               ...          ...             ...        ...   \n1594            6.2             0.600         0.08             2.0      0.090   \n1595            5.9             0.550         0.10             2.2      0.062   \n1596            6.3             0.510         0.13             2.3      0.076   \n1597            5.9             0.645         0.12             2.0      0.075   \n1598            6.0             0.310         0.47             3.6      0.067   \n\n      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n0                    11.0                  34.0  0.99780  3.51       0.56   \n1                    25.0                  67.0  0.99680  3.20       0.68   \n2                    15.0                  54.0  0.99700  3.26       0.65   \n3                    17.0                  60.0  0.99800  3.16       0.58   \n4                    11.0                  34.0  0.99780  3.51       0.56   \n...                   ...                   ...      ...   ...        ...   \n1594                 32.0                  44.0  0.99490  3.45       0.58   \n1595                 39.0                  51.0  0.99512  3.52       0.76   \n1596                 29.0                  40.0  0.99574  3.42       0.75   \n1597                 32.0                  44.0  0.99547  3.57       0.71   \n1598                 18.0                  42.0  0.99549  3.39       0.66   \n\n      alcohol  quality  \n0         9.4        0  \n1         9.8        0  \n2         9.8        0  \n3         9.8        1  \n4         9.4        0  \n...       ...      ...  \n1594     10.5        0  \n1595     11.2        1  \n1596     11.0        1  \n1597     10.2        0  \n1598     11.0        1  \n\n[1599 rows x 12 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>fixed acidity</th>\n      <th>volatile acidity</th>\n      <th>citric acid</th>\n      <th>residual sugar</th>\n      <th>chlorides</th>\n      <th>free sulfur dioxide</th>\n      <th>total sulfur dioxide</th>\n      <th>density</th>\n      <th>pH</th>\n      <th>sulphates</th>\n      <th>alcohol</th>\n      <th>quality</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>7.4</td>\n      <td>0.700</td>\n      <td>0.00</td>\n      <td>1.9</td>\n      <td>0.076</td>\n      <td>11.0</td>\n      <td>34.0</td>\n      <td>0.99780</td>\n      <td>3.51</td>\n      <td>0.56</td>\n      <td>9.4</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7.8</td>\n      <td>0.880</td>\n      <td>0.00</td>\n      <td>2.6</td>\n      <td>0.098</td>\n      <td>25.0</td>\n      <td>67.0</td>\n      <td>0.99680</td>\n      <td>3.20</td>\n      <td>0.68</td>\n      <td>9.8</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>7.8</td>\n      <td>0.760</td>\n      <td>0.04</td>\n      <td>2.3</td>\n      <td>0.092</td>\n      <td>15.0</td>\n      <td>54.0</td>\n      <td>0.99700</td>\n      <td>3.26</td>\n      <td>0.65</td>\n      <td>9.8</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>11.2</td>\n      <td>0.280</td>\n      <td>0.56</td>\n      <td>1.9</td>\n      <td>0.075</td>\n      <td>17.0</td>\n      <td>60.0</td>\n      <td>0.99800</td>\n      <td>3.16</td>\n      <td>0.58</td>\n      <td>9.8</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7.4</td>\n      <td>0.700</td>\n      <td>0.00</td>\n      <td>1.9</td>\n      <td>0.076</td>\n      <td>11.0</td>\n      <td>34.0</td>\n      <td>0.99780</td>\n      <td>3.51</td>\n      <td>0.56</td>\n      <td>9.4</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1594</th>\n      <td>6.2</td>\n      <td>0.600</td>\n      <td>0.08</td>\n      <td>2.0</td>\n      <td>0.090</td>\n      <td>32.0</td>\n      <td>44.0</td>\n      <td>0.99490</td>\n      <td>3.45</td>\n      <td>0.58</td>\n      <td>10.5</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1595</th>\n      <td>5.9</td>\n      <td>0.550</td>\n      <td>0.10</td>\n      <td>2.2</td>\n      <td>0.062</td>\n      <td>39.0</td>\n      <td>51.0</td>\n      <td>0.99512</td>\n      <td>3.52</td>\n      <td>0.76</td>\n      <td>11.2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1596</th>\n      <td>6.3</td>\n      <td>0.510</td>\n      <td>0.13</td>\n      <td>2.3</td>\n      <td>0.076</td>\n      <td>29.0</td>\n      <td>40.0</td>\n      <td>0.99574</td>\n      <td>3.42</td>\n      <td>0.75</td>\n      <td>11.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1597</th>\n      <td>5.9</td>\n      <td>0.645</td>\n      <td>0.12</td>\n      <td>2.0</td>\n      <td>0.075</td>\n      <td>32.0</td>\n      <td>44.0</td>\n      <td>0.99547</td>\n      <td>3.57</td>\n      <td>0.71</td>\n      <td>10.2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1598</th>\n      <td>6.0</td>\n      <td>0.310</td>\n      <td>0.47</td>\n      <td>3.6</td>\n      <td>0.067</td>\n      <td>18.0</td>\n      <td>42.0</td>\n      <td>0.99549</td>\n      <td>3.39</td>\n      <td>0.66</td>\n      <td>11.0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>1599 rows Ã— 12 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# working on the target: 0 for bad and 1 for good\n",
    "df['quality'] = df['quality'].apply(lambda x: 0 if x in [3, 4, 5] else 1)\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of red win of good quality in the target: 53.47%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Proportion of red win of good quality in the target: {round(df['quality'][df['quality']==1].count()/len(df) * 100, 2)}%\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Feature Engineering"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "15cf041b",
   "metadata": {},
   "source": [
    "There is 1599 samples. We can either shuffle all the row of this dataset and then split it in training and testing sets by hand, or we can use scikit learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08e9dea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# frac=1 to shuffle the dataframe + reset the index\n",
    "df_shuffle = df.sample(frac=1).reset_index(drop=True)\n",
    "df_train = df.head(1000)\n",
    "df_test = df.tail(599)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's split the dataset as 70% for the training set and the rest for the testing set. I will only use scikit learn."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n929             8.7             0.330         0.38             3.3      0.063   \n310            10.3             0.530         0.48             2.5      0.063   \n1143            7.0             0.220         0.30             1.8      0.065   \n50              8.8             0.660         0.26             1.7      0.074   \n8               7.8             0.580         0.02             2.0      0.073   \n...             ...               ...          ...             ...        ...   \n1118            7.1             0.390         0.12             2.1      0.065   \n324            10.0             0.490         0.20            11.0      0.071   \n480            10.6             0.280         0.39            15.5      0.069   \n445             9.5             0.735         0.10             2.1      0.079   \n1180            8.2             0.350         0.33             2.4      0.076   \n\n      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n929                  10.0                  19.0  0.99468  3.30       0.73   \n310                   6.0                  25.0  0.99980  3.12       0.59   \n1143                 16.0                  20.0  0.99672  3.61       0.82   \n50                    4.0                  23.0  0.99710  3.15       0.74   \n8                     9.0                  18.0  0.99680  3.36       0.57   \n...                   ...                   ...      ...   ...        ...   \n1118                 14.0                  24.0  0.99252  3.30       0.53   \n324                  13.0                  50.0  1.00150  3.16       0.69   \n480                   6.0                  23.0  1.00260  3.12       0.66   \n445                   6.0                  31.0  0.99860  3.23       0.56   \n1180                 11.0                  47.0  0.99599  3.27       0.81   \n\n      alcohol  \n929      12.0  \n310       9.3  \n1143     10.0  \n50        9.2  \n8         9.5  \n...       ...  \n1118     13.3  \n324       9.2  \n480       9.2  \n445      10.1  \n1180     11.0  \n\n[1119 rows x 11 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>fixed acidity</th>\n      <th>volatile acidity</th>\n      <th>citric acid</th>\n      <th>residual sugar</th>\n      <th>chlorides</th>\n      <th>free sulfur dioxide</th>\n      <th>total sulfur dioxide</th>\n      <th>density</th>\n      <th>pH</th>\n      <th>sulphates</th>\n      <th>alcohol</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>929</th>\n      <td>8.7</td>\n      <td>0.330</td>\n      <td>0.38</td>\n      <td>3.3</td>\n      <td>0.063</td>\n      <td>10.0</td>\n      <td>19.0</td>\n      <td>0.99468</td>\n      <td>3.30</td>\n      <td>0.73</td>\n      <td>12.0</td>\n    </tr>\n    <tr>\n      <th>310</th>\n      <td>10.3</td>\n      <td>0.530</td>\n      <td>0.48</td>\n      <td>2.5</td>\n      <td>0.063</td>\n      <td>6.0</td>\n      <td>25.0</td>\n      <td>0.99980</td>\n      <td>3.12</td>\n      <td>0.59</td>\n      <td>9.3</td>\n    </tr>\n    <tr>\n      <th>1143</th>\n      <td>7.0</td>\n      <td>0.220</td>\n      <td>0.30</td>\n      <td>1.8</td>\n      <td>0.065</td>\n      <td>16.0</td>\n      <td>20.0</td>\n      <td>0.99672</td>\n      <td>3.61</td>\n      <td>0.82</td>\n      <td>10.0</td>\n    </tr>\n    <tr>\n      <th>50</th>\n      <td>8.8</td>\n      <td>0.660</td>\n      <td>0.26</td>\n      <td>1.7</td>\n      <td>0.074</td>\n      <td>4.0</td>\n      <td>23.0</td>\n      <td>0.99710</td>\n      <td>3.15</td>\n      <td>0.74</td>\n      <td>9.2</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>7.8</td>\n      <td>0.580</td>\n      <td>0.02</td>\n      <td>2.0</td>\n      <td>0.073</td>\n      <td>9.0</td>\n      <td>18.0</td>\n      <td>0.99680</td>\n      <td>3.36</td>\n      <td>0.57</td>\n      <td>9.5</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1118</th>\n      <td>7.1</td>\n      <td>0.390</td>\n      <td>0.12</td>\n      <td>2.1</td>\n      <td>0.065</td>\n      <td>14.0</td>\n      <td>24.0</td>\n      <td>0.99252</td>\n      <td>3.30</td>\n      <td>0.53</td>\n      <td>13.3</td>\n    </tr>\n    <tr>\n      <th>324</th>\n      <td>10.0</td>\n      <td>0.490</td>\n      <td>0.20</td>\n      <td>11.0</td>\n      <td>0.071</td>\n      <td>13.0</td>\n      <td>50.0</td>\n      <td>1.00150</td>\n      <td>3.16</td>\n      <td>0.69</td>\n      <td>9.2</td>\n    </tr>\n    <tr>\n      <th>480</th>\n      <td>10.6</td>\n      <td>0.280</td>\n      <td>0.39</td>\n      <td>15.5</td>\n      <td>0.069</td>\n      <td>6.0</td>\n      <td>23.0</td>\n      <td>1.00260</td>\n      <td>3.12</td>\n      <td>0.66</td>\n      <td>9.2</td>\n    </tr>\n    <tr>\n      <th>445</th>\n      <td>9.5</td>\n      <td>0.735</td>\n      <td>0.10</td>\n      <td>2.1</td>\n      <td>0.079</td>\n      <td>6.0</td>\n      <td>31.0</td>\n      <td>0.99860</td>\n      <td>3.23</td>\n      <td>0.56</td>\n      <td>10.1</td>\n    </tr>\n    <tr>\n      <th>1180</th>\n      <td>8.2</td>\n      <td>0.350</td>\n      <td>0.33</td>\n      <td>2.4</td>\n      <td>0.076</td>\n      <td>11.0</td>\n      <td>47.0</td>\n      <td>0.99599</td>\n      <td>3.27</td>\n      <td>0.81</td>\n      <td>11.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1119 rows Ã— 11 columns</p>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wo_target = df.drop('quality', axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_wo_target, df['quality'], test_size=0.30)\n",
    "X_train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Then we can scale the data to optimize the result"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = pd.DataFrame(scaler.fit_transform(X_train), columns=df_wo_target.columns)\n",
    "X_test = pd.DataFrame(scaler.fit_transform(X_test), columns=df_wo_target.columns)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "b55707f2",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "To begin with, I will use a simple algorithm for this classification problem: decision trees."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fitting a first Model: Decision Trees"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7bb494ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "DecisionTreeClassifier(max_depth=3)"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize decision tree classifier class with a max_depth of 3\n",
    "trees_3 = tree.DecisionTreeClassifier(max_depth=3)\n",
    "\n",
    "# cols = df.loc[:, df.columns != 'quality'].columns.tolist()\n",
    "cols = [\n",
    "    'fixed acidity',\n",
    "    'volatile acidity',\n",
    "    'citric acid',\n",
    "    'residual sugar',\n",
    "    'chlorides',\n",
    "    'free sulfur dioxide',\n",
    "    'total sulfur dioxide',\n",
    "    'density',\n",
    "    'pH',\n",
    "    'sulphates',\n",
    "    'alcohol'\n",
    "]\n",
    "\n",
    "trees_3.fit(X_train[cols], y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53edc01a",
   "metadata": {},
   "source": [
    "### Accuracy of this Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0a82d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating predictions on the training and testing sets\n",
    "train_predict_3 = trees_3.predict(X_train[cols])\n",
    "test_predict_3 = trees_3.predict(X_test[cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "(0.7515638963360143, 0.7125)"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculating the accuracy of the predictions on the training and testing sets\n",
    "train_acc_3 = metrics.accuracy_score(y_train, train_predict_3)\n",
    "test_acc_3 = metrics.accuracy_score(y_test, test_predict_3)\n",
    "\n",
    "train_acc_3, test_acc_3"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "(0.8811438784629133, 0.7166666666666667)"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Trying with max_depth=7\n",
    "trees_8 = tree.DecisionTreeClassifier(max_depth=8)\n",
    "trees_8.fit(X_train[cols], y_train)\n",
    "\n",
    "train_predict_8 = trees_8.predict(X_train[cols])\n",
    "test_predict_8 = trees_8.predict(X_test[cols])\n",
    "\n",
    "train_acc_8 = metrics.accuracy_score(y_train, train_predict_8)\n",
    "test_acc_8 = metrics.accuracy_score(y_test, test_predict_8)\n",
    "\n",
    "train_acc_8, test_acc_8"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "20b2303d",
   "metadata": {},
   "source": [
    "### Getting the best max_depth value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "23e39f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing accuracies for training and testing sets from 50% of accuracy\n",
    "l_train_acc = [0.3]\n",
    "l_test_acc = [0.3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ead666b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in range(1, 25):\n",
    "    trees = tree.DecisionTreeClassifier(max_depth=d)\n",
    "    trees.fit(X_train[cols], y_train)\n",
    "    train_predict = trees.predict(X_train[cols])\n",
    "    test_predict = trees.predict(X_test[cols])\n",
    "    l_train_acc.append(metrics.accuracy_score(y_train, train_predict))\n",
    "    l_test_acc.append(metrics.accuracy_score(y_test, test_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 720x360 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(l_train_acc, label=\"train accuracy\")\n",
    "plt.plot(l_test_acc, label=\"test accuracy\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.xlabel(\"max_depth\", size=20)\n",
    "plt.ylabel(\"accuracy\", size=20)\n",
    "plt.grid()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "ca9b2f28",
   "metadata": {},
   "source": [
    "Here the best score is when the max_depth has a value of 9.\n",
    "When we increase the max_depth value, the training accuracy keeps increasing until 100% but the testing accuracy remains the same or gets worse. We can conclude that the decision trees model implemented here keeps learning for the training set more we increase the max_depth value but the performance on the testing set does not improve.\n",
    "\n",
    "=> overfitting\n",
    "\n",
    "As we increase the max_depth value, we will get higher accuracies for the training set but will not provide similar result with real data."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fitting Several Machine Learning Models: Model Selection"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Models Used"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [],
   "source": [
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'Linear Discriminant Analysis': LinearDiscriminantAnalysis(),\n",
    "    'Quadratic Discriminant Analysis': QuadraticDiscriminantAnalysis(),\n",
    "    'SVM - Classifier': SVC(),\n",
    "    'Stochastic Gradient Descent Classifier': SGDClassifier(),\n",
    "    'NaÃ¯ve Bayes': GaussianNB(),\n",
    "    'Decision Trees': DecisionTreeClassifier(),\n",
    "    'Bagging': BaggingClassifier(),\n",
    "    'AdaBoost': AdaBoostClassifier(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'KNN': KNeighborsClassifier()\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "data": {
      "text/plain": "Empty DataFrame\nColumns: []\nIndex: [Logistic Regression, Linear Discriminant Analysis, Quadratic Discriminant Analysis, SVM - Classifier, Stochastic Gradient Descent Classifier, NaÃ¯ve Bayes, Decision Trees, Bagging, AdaBoost, Random Forest, KNN]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Logistic Regression</th>\n    </tr>\n    <tr>\n      <th>Linear Discriminant Analysis</th>\n    </tr>\n    <tr>\n      <th>Quadratic Discriminant Analysis</th>\n    </tr>\n    <tr>\n      <th>SVM - Classifier</th>\n    </tr>\n    <tr>\n      <th>Stochastic Gradient Descent Classifier</th>\n    </tr>\n    <tr>\n      <th>NaÃ¯ve Bayes</th>\n    </tr>\n    <tr>\n      <th>Decision Trees</th>\n    </tr>\n    <tr>\n      <th>Bagging</th>\n    </tr>\n    <tr>\n      <th>AdaBoost</th>\n    </tr>\n    <tr>\n      <th>Random Forest</th>\n    </tr>\n    <tr>\n      <th>KNN</th>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result = pd.DataFrame(index=list(models.keys()))\n",
    "df_result"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:29<00:00,  2.72s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                        accuracy_kfold_5  accuracy_kfold_6  \\\nLogistic Regression                             0.739045          0.737211   \nLinear Discriminant Analysis                    0.748875          0.744370   \nQuadratic Discriminant Analysis                 0.716716          0.716659   \nSVM - Classifier                                0.760510          0.763168   \nStochastic Gradient Descent Classifier          0.672910          0.652296   \nNaÃ¯ve Bayes                                     0.726541          0.734518   \nDecision Trees                                  0.714017          0.714024   \nBagging                                         0.771228          0.764969   \nAdaBoost                                        0.720299          0.739913   \nRandom Forest                                   0.796232          0.795364   \nKNN                                             0.707763          0.699744   \n\n                                        accuracy_kfold_7  accuracy_kfold_8  \\\nLogistic Regression                             0.739937          0.740840   \nLinear Discriminant Analysis                    0.742616          0.744418   \nQuadratic Discriminant Analysis                 0.721187          0.722989   \nSVM - Classifier                                0.756918          0.756950   \nStochastic Gradient Descent Classifier          0.682783          0.693512   \nNaÃ¯ve Bayes                                     0.730133          0.731032   \nDecision Trees                                  0.748894          0.718525   \nBagging                                         0.773911          0.763200   \nAdaBoost                                        0.723854          0.729220   \nRandom Forest                                   0.791779          0.797142   \nKNN                                             0.707777          0.707798   \n\n                                        accuracy_kfold_9  accuracy_kfold_10  \\\nLogistic Regression                             0.739025           0.737275   \nLinear Discriminant Analysis                    0.740810           0.742632   \nQuadratic Discriminant Analysis                 0.715720           0.722112   \nSVM - Classifier                                0.755161           0.763216   \nStochastic Gradient Descent Classifier          0.672789           0.691659   \nNaÃ¯ve Bayes                                     0.730989           0.735505   \nDecision Trees                                  0.741663           0.747144   \nBagging                                         0.776566           0.781065   \nAdaBoost                                        0.742645           0.732794   \nRandom Forest                                   0.796258           0.801617   \nKNN                                             0.701534           0.705993   \n\n                                        accuracy_kfold_11  accuracy_kfold_12  \\\nLogistic Regression                              0.734535           0.735482   \nLinear Discriminant Analysis                     0.736344           0.740849   \nQuadratic Discriminant Analysis                  0.722049           0.722985   \nSVM - Classifier                                 0.763162           0.763269   \nStochastic Gradient Descent Classifier           0.716701           0.702356   \nNaÃ¯ve Bayes                                      0.724722           0.731917   \nDecision Trees                                   0.723019           0.735501   \nBagging                                          0.773010           0.766758   \nAdaBoost                                         0.725614           0.740858   \nRandom Forest                                    0.790906           0.788216   \nKNN                                              0.710453           0.714081   \n\n                                        accuracy_kfold_13  accuracy_kfold_14  \\\nLogistic Regression                              0.737287           0.739048   \nLinear Discriminant Analysis                     0.740865           0.739953   \nQuadratic Discriminant Analysis                  0.719388           0.723926   \nSVM - Classifier                                 0.765920           0.758748   \nStochastic Gradient Descent Classifier           0.677390           0.672028   \nNaÃ¯ve Bayes                                      0.732784           0.733714   \nDecision Trees                                   0.732795           0.754238   \nBagging                                          0.781126           0.779306   \nAdaBoost                                         0.718514           0.731894   \nRandom Forest                                    0.797185           0.805176   \nKNN                                              0.710474           0.715778   \n\n                                        accuracy_kfold_15  \nLogistic Regression                              0.734559  \nLinear Discriminant Analysis                     0.740793  \nQuadratic Discriminant Analysis                  0.723892  \nSVM - Classifier                                 0.764012  \nStochastic Gradient Descent Classifier           0.704192  \nNaÃ¯ve Bayes                                      0.732745  \nDecision Trees                                   0.757778  \nBagging                                          0.768601  \nAdaBoost                                         0.737201  \nRandom Forest                                    0.792589  \nKNN                                              0.715856  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>accuracy_kfold_5</th>\n      <th>accuracy_kfold_6</th>\n      <th>accuracy_kfold_7</th>\n      <th>accuracy_kfold_8</th>\n      <th>accuracy_kfold_9</th>\n      <th>accuracy_kfold_10</th>\n      <th>accuracy_kfold_11</th>\n      <th>accuracy_kfold_12</th>\n      <th>accuracy_kfold_13</th>\n      <th>accuracy_kfold_14</th>\n      <th>accuracy_kfold_15</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Logistic Regression</th>\n      <td>0.739045</td>\n      <td>0.737211</td>\n      <td>0.739937</td>\n      <td>0.740840</td>\n      <td>0.739025</td>\n      <td>0.737275</td>\n      <td>0.734535</td>\n      <td>0.735482</td>\n      <td>0.737287</td>\n      <td>0.739048</td>\n      <td>0.734559</td>\n    </tr>\n    <tr>\n      <th>Linear Discriminant Analysis</th>\n      <td>0.748875</td>\n      <td>0.744370</td>\n      <td>0.742616</td>\n      <td>0.744418</td>\n      <td>0.740810</td>\n      <td>0.742632</td>\n      <td>0.736344</td>\n      <td>0.740849</td>\n      <td>0.740865</td>\n      <td>0.739953</td>\n      <td>0.740793</td>\n    </tr>\n    <tr>\n      <th>Quadratic Discriminant Analysis</th>\n      <td>0.716716</td>\n      <td>0.716659</td>\n      <td>0.721187</td>\n      <td>0.722989</td>\n      <td>0.715720</td>\n      <td>0.722112</td>\n      <td>0.722049</td>\n      <td>0.722985</td>\n      <td>0.719388</td>\n      <td>0.723926</td>\n      <td>0.723892</td>\n    </tr>\n    <tr>\n      <th>SVM - Classifier</th>\n      <td>0.760510</td>\n      <td>0.763168</td>\n      <td>0.756918</td>\n      <td>0.756950</td>\n      <td>0.755161</td>\n      <td>0.763216</td>\n      <td>0.763162</td>\n      <td>0.763269</td>\n      <td>0.765920</td>\n      <td>0.758748</td>\n      <td>0.764012</td>\n    </tr>\n    <tr>\n      <th>Stochastic Gradient Descent Classifier</th>\n      <td>0.672910</td>\n      <td>0.652296</td>\n      <td>0.682783</td>\n      <td>0.693512</td>\n      <td>0.672789</td>\n      <td>0.691659</td>\n      <td>0.716701</td>\n      <td>0.702356</td>\n      <td>0.677390</td>\n      <td>0.672028</td>\n      <td>0.704192</td>\n    </tr>\n    <tr>\n      <th>NaÃ¯ve Bayes</th>\n      <td>0.726541</td>\n      <td>0.734518</td>\n      <td>0.730133</td>\n      <td>0.731032</td>\n      <td>0.730989</td>\n      <td>0.735505</td>\n      <td>0.724722</td>\n      <td>0.731917</td>\n      <td>0.732784</td>\n      <td>0.733714</td>\n      <td>0.732745</td>\n    </tr>\n    <tr>\n      <th>Decision Trees</th>\n      <td>0.714017</td>\n      <td>0.714024</td>\n      <td>0.748894</td>\n      <td>0.718525</td>\n      <td>0.741663</td>\n      <td>0.747144</td>\n      <td>0.723019</td>\n      <td>0.735501</td>\n      <td>0.732795</td>\n      <td>0.754238</td>\n      <td>0.757778</td>\n    </tr>\n    <tr>\n      <th>Bagging</th>\n      <td>0.771228</td>\n      <td>0.764969</td>\n      <td>0.773911</td>\n      <td>0.763200</td>\n      <td>0.776566</td>\n      <td>0.781065</td>\n      <td>0.773010</td>\n      <td>0.766758</td>\n      <td>0.781126</td>\n      <td>0.779306</td>\n      <td>0.768601</td>\n    </tr>\n    <tr>\n      <th>AdaBoost</th>\n      <td>0.720299</td>\n      <td>0.739913</td>\n      <td>0.723854</td>\n      <td>0.729220</td>\n      <td>0.742645</td>\n      <td>0.732794</td>\n      <td>0.725614</td>\n      <td>0.740858</td>\n      <td>0.718514</td>\n      <td>0.731894</td>\n      <td>0.737201</td>\n    </tr>\n    <tr>\n      <th>Random Forest</th>\n      <td>0.796232</td>\n      <td>0.795364</td>\n      <td>0.791779</td>\n      <td>0.797142</td>\n      <td>0.796258</td>\n      <td>0.801617</td>\n      <td>0.790906</td>\n      <td>0.788216</td>\n      <td>0.797185</td>\n      <td>0.805176</td>\n      <td>0.792589</td>\n    </tr>\n    <tr>\n      <th>KNN</th>\n      <td>0.707763</td>\n      <td>0.699744</td>\n      <td>0.707777</td>\n      <td>0.707798</td>\n      <td>0.701534</td>\n      <td>0.705993</td>\n      <td>0.710453</td>\n      <td>0.714081</td>\n      <td>0.710474</td>\n      <td>0.715778</td>\n      <td>0.715856</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for f in tqdm(range(5, 16)):\n",
    "    l_results = []\n",
    "    for k, v in models.items():\n",
    "        kfolds = KFold(n_splits=f)\n",
    "        cross_validation = cross_val_score(v, X_train, y_train, cv=kfolds, scoring='accuracy')\n",
    "        l_results.append(cross_validation.mean())\n",
    "    df_result.loc[:, f'accuracy_kfold_{f}'] = l_results\n",
    "\n",
    "df_result"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['Random Forest', 'Bagging', 'SVM - Classifier', 'Decision Trees',\n       'Linear Discriminant Analysis', 'Logistic Regression', 'NaÃ¯ve Bayes',\n       'AdaBoost', 'Quadratic Discriminant Analysis', 'KNN',\n       'Stochastic Gradient Descent Classifier'],\n      dtype='object')"
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result.sort_values(by='accuracy_kfold_14', ascending=False).index"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here, we will implemented the best 5 models: Random Forest, Bagging, SVC, Decision Trees and LDA. We will try also to implement a XGBoost model."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prediction"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [],
   "source": [
    "def grid_search_models(model_fitted, params, kfolds):\n",
    "    grid_search_model = GridSearchCV(model_fitted, param_grid=params, scoring='accuracy', cv=kfolds)\n",
    "    grid_search_model.fit(X_train, y_train)\n",
    "    return grid_search_model.best_params_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### SVM - Classifier"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [
    {
     "data": {
      "text/plain": "0.7520833333333333"
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_svc = SVC()\n",
    "model_svc.fit(X_train, y_train)\n",
    "pred_model_svc = model_svc.predict(X_test)\n",
    "model_svc.score(X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [],
   "source": [
    "params_svc = {\n",
    "    'kernel': ('linear', 'poly', 'rbf', 'sigmoid'),\n",
    "    'C': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 1.1, 1.2, 1.3, 1.4, 1.5, 1.6, 1.7, 1.8, 1.9, 2.0],\n",
    "    'degree': [3, 8],\n",
    "    # 'coef0': [0.01, 10, 0.5],\n",
    "    'gamma' : ('auto', 'scale'),\n",
    "}\n",
    "\n",
    "d_best_params_svc = grid_search_models(model_svc, params_svc, 14)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [
    {
     "data": {
      "text/plain": "0.7666666666666667"
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_svc = SVC(**d_best_params_svc)\n",
    "model_svc.fit(X_train, y_train)\n",
    "pred_model_svc = model_svc.predict(X_test)\n",
    "model_svc.score(X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### LDA"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [
    {
     "data": {
      "text/plain": "0.7416666666666667"
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lda = LinearDiscriminantAnalysis()\n",
    "model_lda.fit(X_train, y_train)\n",
    "pred_model_lda = model_lda.predict(X_test)\n",
    "model_lda.score(X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid parameter learning_decay for estimator LinearDiscriminantAnalysis(). Check the list of available parameters with `estimator.get_params().keys()`.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_16244/3147357492.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      4\u001B[0m }\n\u001B[0;32m      5\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 6\u001B[1;33m \u001B[0md_best_params_lda\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mgrid_search_models\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel_lda\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mparams_lda\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m14\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_16244/1201752227.py\u001B[0m in \u001B[0;36mgrid_search_models\u001B[1;34m(model_fitted, params, kfolds)\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;32mdef\u001B[0m \u001B[0mgrid_search_models\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel_fitted\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mparams\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkfolds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      2\u001B[0m     \u001B[0mgrid_search_model\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mGridSearchCV\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel_fitted\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mparam_grid\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mparams\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mscoring\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'accuracy'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcv\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mkfolds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 3\u001B[1;33m     \u001B[0mgrid_search_model\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_train\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      4\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0mgrid_search_model\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbest_params_\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\tinou\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, X, y, groups, **fit_params)\u001B[0m\n\u001B[0;32m    889\u001B[0m                 \u001B[1;32mreturn\u001B[0m \u001B[0mresults\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    890\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 891\u001B[1;33m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_run_search\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mevaluate_candidates\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    892\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    893\u001B[0m             \u001B[1;31m# multimetric is determined here because in the case of a callable\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\tinou\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001B[0m in \u001B[0;36m_run_search\u001B[1;34m(self, evaluate_candidates)\u001B[0m\n\u001B[0;32m   1390\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m_run_search\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mevaluate_candidates\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1391\u001B[0m         \u001B[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1392\u001B[1;33m         \u001B[0mevaluate_candidates\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mParameterGrid\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mparam_grid\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1393\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1394\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\tinou\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001B[0m in \u001B[0;36mevaluate_candidates\u001B[1;34m(candidate_params, cv, more_results)\u001B[0m\n\u001B[0;32m    836\u001B[0m                     )\n\u001B[0;32m    837\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 838\u001B[1;33m                 out = parallel(\n\u001B[0m\u001B[0;32m    839\u001B[0m                     delayed(_fit_and_score)(\n\u001B[0;32m    840\u001B[0m                         \u001B[0mclone\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbase_estimator\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\tinou\\lib\\site-packages\\joblib\\parallel.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m   1041\u001B[0m             \u001B[1;31m# remaining jobs.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1042\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_iterating\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mFalse\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1043\u001B[1;33m             \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdispatch_one_batch\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0miterator\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1044\u001B[0m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_iterating\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_original_iterator\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1045\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\tinou\\lib\\site-packages\\joblib\\parallel.py\u001B[0m in \u001B[0;36mdispatch_one_batch\u001B[1;34m(self, iterator)\u001B[0m\n\u001B[0;32m    859\u001B[0m                 \u001B[1;32mreturn\u001B[0m \u001B[1;32mFalse\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    860\u001B[0m             \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 861\u001B[1;33m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_dispatch\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtasks\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    862\u001B[0m                 \u001B[1;32mreturn\u001B[0m \u001B[1;32mTrue\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    863\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\tinou\\lib\\site-packages\\joblib\\parallel.py\u001B[0m in \u001B[0;36m_dispatch\u001B[1;34m(self, batch)\u001B[0m\n\u001B[0;32m    777\u001B[0m         \u001B[1;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_lock\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    778\u001B[0m             \u001B[0mjob_idx\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_jobs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 779\u001B[1;33m             \u001B[0mjob\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_backend\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mapply_async\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbatch\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcallback\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcb\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    780\u001B[0m             \u001B[1;31m# A job can complete so quickly than its callback is\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    781\u001B[0m             \u001B[1;31m# called before we get here, causing self._jobs to\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\tinou\\lib\\site-packages\\joblib\\_parallel_backends.py\u001B[0m in \u001B[0;36mapply_async\u001B[1;34m(self, func, callback)\u001B[0m\n\u001B[0;32m    206\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mapply_async\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfunc\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcallback\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    207\u001B[0m         \u001B[1;34m\"\"\"Schedule a func to be run\"\"\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 208\u001B[1;33m         \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mImmediateResult\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfunc\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    209\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mcallback\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    210\u001B[0m             \u001B[0mcallback\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mresult\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\tinou\\lib\\site-packages\\joblib\\_parallel_backends.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, batch)\u001B[0m\n\u001B[0;32m    570\u001B[0m         \u001B[1;31m# Don't delay the application, to avoid keeping the input\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    571\u001B[0m         \u001B[1;31m# arguments in memory\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 572\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mresults\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mbatch\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    573\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    574\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mget\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\tinou\\lib\\site-packages\\joblib\\parallel.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    260\u001B[0m         \u001B[1;31m# change the default number of processes to -1\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    261\u001B[0m         \u001B[1;32mwith\u001B[0m \u001B[0mparallel_backend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_backend\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mn_jobs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_n_jobs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 262\u001B[1;33m             return [func(*args, **kwargs)\n\u001B[0m\u001B[0;32m    263\u001B[0m                     for func, args, kwargs in self.items]\n\u001B[0;32m    264\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\tinou\\lib\\site-packages\\joblib\\parallel.py\u001B[0m in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    260\u001B[0m         \u001B[1;31m# change the default number of processes to -1\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    261\u001B[0m         \u001B[1;32mwith\u001B[0m \u001B[0mparallel_backend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_backend\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mn_jobs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_n_jobs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 262\u001B[1;33m             return [func(*args, **kwargs)\n\u001B[0m\u001B[0;32m    263\u001B[0m                     for func, args, kwargs in self.items]\n\u001B[0;32m    264\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\tinou\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    209\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m__call__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    210\u001B[0m         \u001B[1;32mwith\u001B[0m \u001B[0mconfig_context\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m**\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mconfig\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 211\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfunction\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    212\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    213\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\tinou\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001B[0m in \u001B[0;36m_fit_and_score\u001B[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001B[0m\n\u001B[0;32m    667\u001B[0m             \u001B[0mcloned_parameters\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mk\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mclone\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mv\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msafe\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mFalse\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    668\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 669\u001B[1;33m         \u001B[0mestimator\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mestimator\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mset_params\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m**\u001B[0m\u001B[0mcloned_parameters\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    670\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    671\u001B[0m     \u001B[0mstart_time\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtime\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtime\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\tinou\\lib\\site-packages\\sklearn\\base.py\u001B[0m in \u001B[0;36mset_params\u001B[1;34m(self, **params)\u001B[0m\n\u001B[0;32m    238\u001B[0m             \u001B[0mkey\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdelim\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msub_key\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mkey\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpartition\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"__\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    239\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mkey\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mvalid_params\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 240\u001B[1;33m                 raise ValueError(\n\u001B[0m\u001B[0;32m    241\u001B[0m                     \u001B[1;34m\"Invalid parameter %s for estimator %s. \"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    242\u001B[0m                     \u001B[1;34m\"Check the list of available parameters \"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: Invalid parameter learning_decay for estimator LinearDiscriminantAnalysis(). Check the list of available parameters with `estimator.get_params().keys()`."
     ]
    }
   ],
   "source": [
    "params_lda = {\n",
    "    'n_components': [10, 15, 20, 25, 30],\n",
    "    'solver': ('lsqr','eigen')\n",
    "}\n",
    "\n",
    "d_best_params_lda = grid_search_models(model_lda, params_lda, 14)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_lda = LinearDiscriminantAnalysis(**d_best_params_lda)\n",
    "model_lda.fit(X_train, y_train)\n",
    "pred_model_lda = model_lda.predict(X_test)\n",
    "model_lda.score(X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Decision Trees"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Bagging"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Random Forest"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### XGBoost"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "data": {
      "text/plain": "0.4054146372928193"
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dmatrix = xgb.DMatrix(data=X_train,label=y_train)\n",
    "xg_reg = xgb.XGBRegressor()\n",
    "xg_reg.fit(X_train, y_train)\n",
    "pred = xg_reg.predict(X_test)\n",
    "np.sqrt(mean_squared_error(y_test, pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_dmatrix = xgb.DMatrix(data=X,label=y)\n",
    "xg_reg = xgb.XGBRegressor(objective ='reg:linear', colsample_bytree = 0.3, learning_rate = 0.1, max_depth = 5, alpha = 10, n_estimators = 10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}